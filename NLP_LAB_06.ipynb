{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SECrwti8ZqTa"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, LSTM, Dense, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step (a): Preprocessing the Data\n",
        "max_features = 10000\n",
        "maxlen = 100"
      ],
      "metadata": {
        "id": "aV0GrF6zce5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data (IMDB dataset)\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsqfCiW2dbOf",
        "outputId": "4b4091e6-23d0-4563-930c-3f1ba8c42dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences (to ensure equal length inputs)\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "nTG5sk2KdhkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step (c): Build the GRU model\n",
        "gru_model = Sequential()\n",
        "gru_model.add(Embedding(max_features, 128))\n",
        "gru_model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "gru_model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "KNWAy3f3d_A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "gru_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "zFzhxi6IeGfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step (d): Training the GRU model\n",
        "gru_model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s1EBqIYeM7G",
        "outputId": "eea6417b-c371-4835-ad3d-ad7ab8ab1aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 203ms/step - accuracy: 0.6326 - loss: 13215.3789 - val_accuracy: 0.6827 - val_loss: 0.5890\n",
            "Epoch 2/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 201ms/step - accuracy: 0.7542 - loss: 12.9658 - val_accuracy: 0.6845 - val_loss: 0.5837\n",
            "Epoch 3/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 212ms/step - accuracy: 0.7759 - loss: 0.4761 - val_accuracy: 0.6912 - val_loss: 0.5870\n",
            "Epoch 4/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 208ms/step - accuracy: 0.8050 - loss: 0.4261 - val_accuracy: 0.6952 - val_loss: 0.5946\n",
            "Epoch 5/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 207ms/step - accuracy: 0.8285 - loss: 0.7048 - val_accuracy: 0.6880 - val_loss: 0.6117\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c872229f790>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Step 1: Load the IMDB dataset (already split into training and test sets)\n",
        "max_features = 10000  # Number of unique words to use (most frequent)\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Optional: Combine x_train and x_test to perform custom splitting\n",
        "data = np.concatenate((x_train, x_test), axis=0)\n",
        "labels = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "# Step 2: Use train_test_split to split the data further\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Pad sequences to ensure uniform input size\n",
        "maxlen = 100  # Max length of review (in words)\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Output shapes to verify\n",
        "print(f\"Training data shape: {x_train.shape}, Training labels shape: {y_train.shape}\")\n",
        "print(f\"Test data shape: {x_test.shape}, Test labels shape: {y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blIHPTGyd1vz",
        "outputId": "e63f82bf-02d9-42f7-be54-ce780e658d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (40000, 100), Training labels shape: (40000,)\n",
            "Test data shape: (10000, 100), Test labels shape: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step (f): Evaluate GRU Model's accuracy\n",
        "gru_score, gru_acc = gru_model.evaluate(x_test, y_test)\n",
        "print(f\"GRU Test Accuracy: {gru_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVTgG8WajCX_",
        "outputId": "63680d3f-ff4a-4ccc-8823-43188e5f93c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.7507 - loss: 0.5138\n",
            "GRU Test Accuracy: 0.7520999908447266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step (c - e) for LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(Embedding(max_features, 128))\n",
        "lstm_model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "0T9IYSR8jeM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ZgSqSuxnji5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step (d): Training the LSTM model\n",
        "lstm_model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCRrndY_mgPC",
        "outputId": "726a238a-eb7a-4827-b940-32a29b1d7c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 211ms/step - accuracy: 0.7422 - loss: 0.5051 - val_accuracy: 0.8540 - val_loss: 0.3469\n",
            "Epoch 2/5\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 206ms/step - accuracy: 0.8673 - loss: 0.3204 - val_accuracy: 0.8550 - val_loss: 0.3303\n",
            "Epoch 3/5\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 204ms/step - accuracy: 0.9026 - loss: 0.2441 - val_accuracy: 0.8633 - val_loss: 0.3468\n",
            "Epoch 4/5\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 202ms/step - accuracy: 0.9295 - loss: 0.1867 - val_accuracy: 0.8576 - val_loss: 0.3408\n",
            "Epoch 5/5\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 202ms/step - accuracy: 0.9445 - loss: 0.1466 - val_accuracy: 0.8552 - val_loss: 0.4078\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c87202f5ea0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step (f): Evaluate LSTM Model's accuracy\n",
        "lstm_score, lstm_acc = lstm_model.evaluate(x_test, y_test)\n",
        "print(f\"LSTM Test Accuracy: {lstm_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoBLV2cliibf",
        "outputId": "d93e5641-ed79-4ff3-9833-9451f56fe409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 64ms/step - accuracy: 0.8593 - loss: 0.3973\n",
            "LSTM Test Accuracy: 0.8551999926567078\n"
          ]
        }
      ]
    }
  ]
}